#!/usr/bin/env python3
"""
Math Reasoning Library å¿«é€Ÿæ¼”ç¤º

å±•ç¤ºé‡æ„åçš„libraryå¦‚ä½•ç®€åŒ–ä¸åŒbenchmarkçš„å¤„ç†æµç¨‹
"""

import os
from math_reasoning_lib.core.pipeline import MathReasoningPipeline
from math_reasoning_lib.core.config import PipelineConfig, get_benchmark_config
from math_reasoning_lib.core.base_classes import MathProblem, BaseBenchmark
from math_reasoning_lib.benchmarks.registry import register_benchmark


class DemoBenchmark(BaseBenchmark):
    """æ¼”ç¤ºç”¨çš„ç®€å•benchmark"""
    
    def __init__(self):
        self.problems_data = [
            {"id": "demo_001", "text": "è®¡ç®— 2 + 3", "answer": "5"},
            {"id": "demo_002", "text": "æ±‚è§£æ–¹ç¨‹ x + 5 = 8", "answer": "x = 3"},
            {"id": "demo_003", "text": "è®¡ç®— 10 çš„å¹³æ–¹æ ¹", "answer": "âˆš10 â‰ˆ 3.16"},
            {"id": "demo_004", "text": "æ±‚ä¸‰è§’å½¢é¢ç§¯ï¼Œåº•è¾¹4ï¼Œé«˜3", "answer": "6"},
            {"id": "demo_005", "text": "åŒ–ç®€ (x + 2)(x - 2)", "answer": "xÂ² - 4"},
        ]
    
    def load_problems(self, num_problems=5, **kwargs):
        problems = []
        for i, data in enumerate(self.problems_data[:num_problems]):
            problem = MathProblem(
                problem_id=data["id"],
                problem_text=data["text"],
                answer=data["answer"]
            )
            problems.append(problem)
        return problems
    
    def load_test_problems(self, num_problems=3, **kwargs):
        return self.load_problems(num_problems, **kwargs)


def demo_single_stage():
    """æ¼”ç¤ºï¼šå•é˜¶æ®µè¿è¡Œ"""
    print("ğŸ”¬ æ¼”ç¤º1: å•é˜¶æ®µæ•°æ®ç”Ÿæˆ")
    print("-" * 40)
    
    # æ³¨å†Œæ¼”ç¤ºbenchmark
    register_benchmark("demo", DemoBenchmark)
    
    # åˆ›å»ºé…ç½®
    config = PipelineConfig()
    
    # åˆ›å»ºç®¡é“
    pipeline = MathReasoningPipeline(config)
    
    # è¿è¡Œæ•°æ®ç”Ÿæˆé˜¶æ®µ
    result = pipeline.run_data_generation(
        benchmark="demo",
        model="mock",
        num_problems=3,
        toolkits=["sympy", "code_execution"]
    )
    
    print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ")
    print(f"   ğŸ“Š å¤„ç†é—®é¢˜æ•°: {result.num_problems}")
    print(f"   ğŸ“ˆ æˆåŠŸç‡: {result.success_rate:.2%}")
    print(f"   ğŸ¯ é˜¶æ®µ: {result.stage}")
    
    return result


def demo_multi_benchmark():
    """æ¼”ç¤ºï¼šå¤šbenchmarkå¯¹æ¯”"""
    print("\nğŸ†š æ¼”ç¤º2: å¤šBenchmarkå¯¹æ¯”")
    print("-" * 40)
    
    # æ³¨å†Œæ¼”ç¤ºbenchmark
    register_benchmark("demo", DemoBenchmark)
    
    benchmarks = ["demo"]  # å¯ä»¥æ‰©å±•ä¸º ["demo", "math", "gsm8k"]
    models = ["mock"]      # å¯ä»¥æ‰©å±•ä¸º ["gpt-4o-mini", "gpt-3.5-turbo"]
    
    results = {}
    
    for benchmark in benchmarks:
        results[benchmark] = {}
        
        for model in models:
            print(f"ğŸ“‹ è¿è¡Œ {benchmark} with {model}")
            
            # è·å–ç‰¹å®šbenchmarkçš„é…ç½®
            if benchmark == "demo":
                config = PipelineConfig()
            else:
                config = PipelineConfig.from_dict(get_benchmark_config(benchmark))
            
            pipeline = MathReasoningPipeline(config)
            
            result = pipeline.run_data_generation(
                benchmark=benchmark,
                model=model,
                num_problems=5,
                toolkits=["sympy"]
            )
            
            results[benchmark][model] = {
                "success_rate": result.success_rate,
                "num_problems": result.num_problems
            }
    
    # æ‰“å°å¯¹æ¯”ç»“æœ
    print("\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    for benchmark, models_data in results.items():
        print(f"\n{benchmark.upper()}:")
        for model, data in models_data.items():
            print(f"  {model}: {data['success_rate']:.2%} ({data['num_problems']} é—®é¢˜)")
    
    return results


def demo_full_pipeline():
    """æ¼”ç¤ºï¼šå®Œæ•´å››é˜¶æ®µç®¡é“"""
    print("\nğŸ”„ æ¼”ç¤º3: å®Œæ•´å››é˜¶æ®µç®¡é“")
    print("-" * 40)
    
    # æ³¨å†Œæ¼”ç¤ºbenchmark
    register_benchmark("demo", DemoBenchmark)
    
    # åˆ›å»ºé…ç½®
    config = PipelineConfig()
    config.training_config.epochs = 1  # å¿«é€Ÿæ¼”ç¤ºï¼Œå‡å°‘è®­ç»ƒæ—¶é—´
    
    # åˆ›å»ºç®¡é“
    pipeline = MathReasoningPipeline(config)
    
    # è¿è¡Œå®Œæ•´ç®¡é“
    print("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´å››é˜¶æ®µç®¡é“...")
    
    results = pipeline.run_full_pipeline(
        benchmark="demo",
        base_model="mock",
        enhancement_model="mock",
        num_problems=3,
        toolkits=["sympy"]
    )
    
    print("\nğŸ“‹ å„é˜¶æ®µç»“æœ:")
    for i, result in enumerate(results, 1):
        status = "âœ…" if result.success_rate > 0 else "âŒ"
        print(f"  {i}. {result.stage}: {status} {result.success_rate:.2%}")
        if result.metrics:
            print(f"     ğŸ“Š æŒ‡æ ‡: {result.metrics}")
    
    return results


def demo_config_flexibility():
    """æ¼”ç¤ºï¼šé…ç½®çµæ´»æ€§"""
    print("\nâš™ï¸ æ¼”ç¤º4: é…ç½®ç³»ç»Ÿçµæ´»æ€§")
    print("-" * 40)
    
    # 1. ä½¿ç”¨é¢„è®¾é…ç½®
    print("ğŸ“ 1. é¢„è®¾é…ç½®:")
    math_config = get_benchmark_config("math")
    print(f"   MATHé…ç½® - æœ€å¤§è¿­ä»£: {math_config['solver']['max_iterations']}")
    
    gsm8k_config = get_benchmark_config("gsm8k")
    print(f"   GSM8Ké…ç½® - æ‰¹æ¬¡å¤§å°: {gsm8k_config['training']['batch_size']}")
    
    # 2. è‡ªå®šä¹‰é…ç½®
    print("\nğŸ”§ 2. è‡ªå®šä¹‰é…ç½®:")
    custom_config = {
        "solver": {
            "max_iterations": 20,
            "timeout": 900,
            "retry_attempts": 5
        },
        "training": {
            "epochs": 1,
            "batch_size": 2,
            "rank": 32
        }
    }
    
    config = PipelineConfig.from_dict(custom_config)
    print(f"   è‡ªå®šä¹‰é…ç½® - æœ€å¤§è¿­ä»£: {config.solver_config.max_iterations}")
    print(f"   è‡ªå®šä¹‰é…ç½® - LoRA rank: {config.training_config.rank}")
    
    # 3. é…ç½®æ–‡ä»¶
    print("\nğŸ’¾ 3. é…ç½®æ–‡ä»¶ä¿å­˜/åŠ è½½:")
    config.save("demo_config.yaml")
    loaded_config = PipelineConfig.from_file("demo_config.yaml")
    print(f"   ä»æ–‡ä»¶åŠ è½½é…ç½®æˆåŠŸ âœ…")
    
    # æ¸…ç†
    if os.path.exists("demo_config.yaml"):
        os.remove("demo_config.yaml")
    
    return config


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¯ Math Reasoning Library åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    print("å±•ç¤ºé‡æ„åçš„libraryå¦‚ä½•ç®€åŒ–ä¸åŒbenchmarkçš„å¤„ç†æµç¨‹")
    print("=" * 50)
    
    try:
        # æ¼”ç¤º1: å•é˜¶æ®µè¿è¡Œ
        demo_single_stage()
        
        # æ¼”ç¤º2: å¤šbenchmarkå¯¹æ¯”
        demo_multi_benchmark()
        
        # æ¼”ç¤º3: å®Œæ•´ç®¡é“
        demo_full_pipeline()
        
        # æ¼”ç¤º4: é…ç½®çµæ´»æ€§
        demo_config_flexibility()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ å…³é”®ä¼˜åŠ¿:")
        print("âœ… ç»Ÿä¸€æ¥å£ - ä¸åŒbenchmarkä½¿ç”¨ç›¸åŒAPI")
        print("âœ… æ¨¡å—åŒ–è®¾è®¡ - æ¯ä¸ªç»„ä»¶ç‹¬ç«‹å¯æµ‹è¯•")
        print("âœ… çµæ´»é…ç½® - æ”¯æŒå¤šç§é…ç½®æ–¹å¼")
        print("âœ… æ˜“äºæ‰©å±• - ç®€å•æ³¨å†Œæ–°benchmark")
        print("âœ… å‡å°‘é‡å¤ - 90%çš„ä»£ç å¯å¤ç”¨")
        
        print("\nğŸ“š ä¸‹ä¸€æ­¥:")
        print("1. æ·»åŠ çœŸå®çš„æ¨¡å‹æ¥å£ï¼ˆOpenAI, Anthropicç­‰ï¼‰")
        print("2. å®ç°å…·ä½“çš„å·¥å…·åŒ…ï¼ˆSymPy, Code Executionç­‰ï¼‰")
        print("3. æ·»åŠ æ›´å¤šbenchmarkï¼ˆMATH, GSM8K, AIMEç­‰ï¼‰")
        print("4. å®Œå–„è®­ç»ƒå’Œè¯„ä¼°æ¨¡å—")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 